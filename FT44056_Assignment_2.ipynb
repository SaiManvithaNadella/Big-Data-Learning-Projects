{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "smwrIhF1TIur",
    "outputId": "25eadbf1-186f-46c0-829e-0df888471fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "dh2qZv5nTXGn",
    "outputId": "cbfee432-1ddd-418f-8070-b8aff86fe4e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyenchant\n",
      "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m927.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyenchant\n",
      "Successfully installed pyenchant-3.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyenchant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vxKzrnxiSyOq"
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# My Date of birth is 26th October 2000, so defining my birth month, date and year\n",
    "birth_month = 10\n",
    "birth_date = 26\n",
    "birth_year = 100\n",
    "\n",
    "# Calculating the pages to extract data for file1.txt and file2.txt\n",
    "file1_start_page = birth_date\n",
    "file1_end_page = birth_date + 9\n",
    "file2_start_page = birth_year\n",
    "file2_end_page = birth_year + 9\n",
    "\n",
    "# Function to extract text from a range of pages\n",
    "pdf_path = '/content/Harry_Potter_(www.ztcprep.com).pdf'\n",
    "pdf_file = open(pdf_path, 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "def extract_text_from_range(pdf_reader, start_page, end_page):\n",
    "    text = ''\n",
    "    for page_num in range(start_page, end_page+1):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Writing the text into the files\n",
    "file1_text = extract_text_from_range(pdf_reader, file1_start_page, file1_end_page)\n",
    "file2_text = extract_text_from_range(pdf_reader, file2_start_page, file2_end_page)\n",
    "with open('file1.txt', 'w') as file1:\n",
    "    file1.write(file1_text)\n",
    "with open('file2.txt', 'w') as file2:\n",
    "    file2.write(file2_text)\n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "VfyordflT1w8",
    "outputId": "63b90080-f959-4bc4-f017-9fbe49b91979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",:13\n",
      ",”:4\n",
      ".:15\n",
      ".”:4\n",
      "15:1\n",
      "16:1\n",
      "17:1\n",
      "18:1\n",
      "19:1\n",
      "20:1\n",
      "21:1\n",
      "?”:1\n",
      "a:47\n",
      "about:3\n",
      "above:1\n",
      "after:2\n",
      "again.:1\n",
      "age.:1\n",
      "ago,:1\n",
      "air:2\n",
      "all:7\n",
      "all.:1\n",
      "allowed,:1\n",
      "almost:4\n",
      "always:1\n",
      "anashig:1\n",
      "and:51\n",
      "and,:1\n",
      "another:1\n",
      "an’:2\n",
      "arm:1\n",
      "arms:2\n",
      "around:2\n",
      "around.:1\n",
      "as:16\n",
      "asked:1\n",
      "asleep:2\n",
      "asleep.:1\n",
      "astonishing:1\n",
      "astride:1\n",
      "at:9\n",
      "aunt:4\n",
      "awake:1\n",
      "away:2\n",
      "baby:3\n",
      "back:5\n",
      "bacon.:1\n",
      "bag:1\n",
      "ball:1\n",
      "balls:1\n",
      "be:4\n",
      "beach:1\n",
      "beard:1\n",
      "because:2\n",
      "bed:2\n",
      "been:7\n",
      "before:1\n",
      "before.:1\n",
      "being:3\n",
      "beneath:1\n",
      "bent:2\n",
      "beside:1\n",
      "best:1\n",
      "better:1\n",
      "bicycle,:1\n",
      "big:1\n",
      "bigger:1\n",
      "bike:2\n",
      "bike.:1\n",
      "birthday:3\n",
      "black:3\n",
      "blankets:2\n",
      "blankets,:1\n",
      "blankets.:2\n",
      "blew:1\n",
      "blinked:1\n",
      "blond:1\n",
      "bolt:1\n",
      "bonnets:1\n",
      "boots:1\n",
      "both:1\n",
      "bottles,:1\n",
      "boy:5\n",
      "brass:1\n",
      "breeze:1\n",
      "bright:1\n",
      "bringing:1\n",
      "bristol.”:1\n",
      "broken:1\n",
      "bundle:3\n",
      "bundle;:1\n",
      "burn,:1\n",
      "burying:1\n",
      "bushy:1\n",
      "business:1\n",
      "but:9\n",
      "by:3\n",
      "c-c-:1\n",
      "came:1\n",
      "can:2\n",
      "can’:2\n",
      "carefully:1\n",
      "careless.:1\n",
      "carousel:1\n",
      "cat:1\n",
      "catch:1\n",
      "celebrations.”:1\n",
      "changed:2\n",
      "clicked:1\n",
      "climbing:1\n",
      "cloak:1\n",
      "cloak,:2\n",
      "closed:1\n",
      "clothes:1\n",
      "come:1\n",
      "computer:2\n",
      "corner:2\n",
      "could:5\n",
      "could,:1\n",
      "couldn’:2\n",
      "country:1\n",
      "course:1\n",
      "course.:1\n",
      "cousin:1\n",
      "crept:1\n",
      "cupboard:1\n",
      "cupboard,:1\n",
      "curiously:1\n",
      "cut,:1\n",
      "dare:1\n",
      "dark:1\n",
      "day:1\n",
      "dead:1\n",
      "demanded.:1\n",
      "destroyed,:1\n",
      "did:2\n",
      "didn’:1\n",
      "dif:1\n",
      "do:2\n",
      "does:1\n",
      "dog.:1\n",
      "dolphins.:1\n",
      "don’:1\n",
      "door:5\n",
      "door;:1\n",
      "doorstep,:1\n",
      "down:3\n",
      "dream:2\n",
      "dressed:1\n",
      "drive:2\n",
      "drive,:1\n",
      "duddy’:1\n",
      "dudley:6\n",
      "dudley’:4\n",
      "dumbledore:5\n",
      "dumbledore,:4\n",
      "dumbledore.:2\n",
      "dumbledore?”:2\n",
      "dumbledore’:1\n",
      "dursley:2\n",
      "dursleys:1\n",
      "dursleys’:2\n",
      "dursley’:1\n",
      "e:8\n",
      "eah,”:1\n",
      "ell:1\n",
      "ell,:1\n",
      "ell,”:1\n",
      "en:1\n",
      "end:1\n",
      "engine:1\n",
      "es:1\n",
      "es,:1\n",
      "es,”:1\n",
      "et:1\n",
      "even:1\n",
      "everything:1\n",
      "exactly:2\n",
      "exercise:1\n",
      "expect:1\n",
      "expect,:1\n",
      "eyed:1\n",
      "eyes:2\n",
      "e’ve:1\n",
      "f:4\n",
      "face:1\n",
      "face,:2\n",
      "fair:1\n",
      "famous,:1\n",
      "fast:1\n",
      "fast.:1\n",
      "fat:1\n",
      "fateful:1\n",
      "father:1\n",
      "favorite:1\n",
      "feeling:1\n",
      "feet:1\n",
      "fell:2\n",
      "ferent-colored:1\n",
      "few:2\n",
      "finally:1\n",
      "find:1\n",
      "first:2\n",
      "five:1\n",
      "fled:2\n",
      "flying:1\n",
      "flyin’:1\n",
      "for:6\n",
      "forehead:1\n",
      "forever:1\n",
      "forward:1\n",
      "found:1\n",
      "found,”:1\n",
      "four:3\n",
      "from:2\n",
      "front:6\n",
      "frying:1\n",
      "full:2\n",
      "funny:1\n",
      "furiously:1\n",
      "g:7\n",
      "game:1\n",
      "garden:1\n",
      "gardens:1\n",
      "gave:1\n",
      "ge:2\n",
      "ge,:1\n",
      "gently:1\n",
      "get:6\n",
      "getting:1\n",
      "giant,:1\n",
      "gingerly:1\n",
      "give:1\n",
      "glass:1\n",
      "glasses:1\n",
      "glowed:1\n",
      "go:1\n",
      "gone:1\n",
      "gone.:1\n",
      "good:1\n",
      "good-bye:1\n",
      "got:3\n",
      "gotten:1\n",
      "gotten?:1\n",
      "great,:1\n",
      "green:1\n",
      "grew:1\n",
      "grip:1\n",
      "groaned.:1\n",
      "ground.:1\n",
      "growing:1\n",
      "grudgingly:1\n",
      "g’night,:1\n",
      "had:19\n",
      "hagrid:7\n",
      "hagrid,:2\n",
      "hagrid.:1\n",
      "hagrid’:1\n",
      "hair:3\n",
      "hall:1\n",
      "hand:1\n",
      "handkerchief:1\n",
      "hands:1\n",
      "handy:1\n",
      "happen.:1\n",
      "hardly:1\n",
      "harry:27\n",
      "harry’:1\n",
      "hated:1\n",
      "have:5\n",
      "having.:1\n",
      "he:38\n",
      "head:1\n",
      "headlight;:1\n",
      "heard:1\n",
      "heart:1\n",
      "hedges:1\n",
      "heel:1\n",
      "held:1\n",
      "her:6\n",
      "here,:2\n",
      "here.:1\n",
      "he’:2\n",
      "he’d:1\n",
      "hid:1\n",
      "hidden:1\n",
      "hiding:1\n",
      "him:4\n",
      "him,:2\n",
      "him.:1\n",
      "him.”:1\n",
      "himself:1\n",
      "his:26\n",
      "hissed:1\n",
      "holding:2\n",
      "hours’:1\n",
      "house:1\n",
      "house,:1\n",
      "house.:1\n",
      "how:3\n",
      "howl:1\n",
      "huge:1\n",
      "huge,:1\n",
      "hugged:1\n",
      "hushed:1\n",
      "i:10\n",
      "if:2\n",
      "important:1\n",
      "in:15\n",
      "inky:1\n",
      "inside:2\n",
      "inside,:1\n",
      "into:5\n",
      "involved:1\n",
      "iping:1\n",
      "is:2\n",
      "isn’:1\n",
      "it:17\n",
      "it,:3\n",
      "it.:4\n",
      "it?”:1\n",
      "it’:1\n",
      "i’ve:1\n",
      "j.k.:7\n",
      "jacket:1\n",
      "james:1\n",
      "jet-black:1\n",
      "join:1\n",
      "just:2\n",
      "kicked:1\n",
      "kiss.:1\n",
      "kissed:1\n",
      "kitchen:1\n",
      "kitchen.:1\n",
      "knee:1\n",
      "knees,:1\n",
      "knobbly:1\n",
      "know:1\n",
      "knowing:3\n",
      "laid:1\n",
      "lamps:1\n",
      "landed:1\n",
      "lar:3\n",
      "last:1\n",
      "last.:1\n",
      "lay:1\n",
      "least:1\n",
      "leather:1\n",
      "left:1\n",
      "lent:1\n",
      "let:2\n",
      "letter:2\n",
      "lids,:1\n",
      "life,”:1\n",
      "life;:1\n",
      "light:2\n",
      "lightning.:1\n",
      "like:4\n",
      "lily:1\n",
      "lit:1\n",
      "little:2\n",
      "live:1\n",
      "lived:1\n",
      "lived!”:1\n",
      "living:2\n",
      "london:1\n",
      "long:1\n",
      "long.:1\n",
      "longer:1\n",
      "look:2\n",
      "looked:7\n",
      "looking:1\n",
      "lots:1\n",
      "louder:1\n",
      "low:2\n",
      "luck,:1\n",
      "made:1\n",
      "make:1\n",
      "man:2\n",
      "mantelpiece:1\n",
      "map:1\n",
      "may:1\n",
      "mcgonagall:7\n",
      "mcgonagall,:1\n",
      "mcgonagall,”:1\n",
      "mcgonagall.:1\n",
      "me.:1\n",
      "meeting:1\n",
      "mention:1\n",
      "might:1\n",
      "milk:1\n",
      "mind,:1\n",
      "minute:1\n",
      "moment,:2\n",
      "most:1\n",
      "mother:1\n",
      "motorcycle:5\n",
      "motorcycle?”:1\n",
      "mouth,:1\n",
      "move:1\n",
      "mr:1\n",
      "mrs.:1\n",
      "much:1\n",
      "muf:1\n",
      "muggles:2\n",
      "muggles!”:1\n",
      "murmured.:1\n",
      "muscular:1\n",
      "must:1\n",
      "my:2\n",
      "myself:1\n",
      "mystery:1\n",
      "nearly:1\n",
      "neat:1\n",
      "nephew:1\n",
      "new:1\n",
      "news:1\n",
      "next:1\n",
      "night:1\n",
      "night.:1\n",
      "no:3\n",
      "nodding:1\n",
      "noise:1\n",
      "nor:1\n",
      "normal:1\n",
      "nose:1\n",
      "not:7\n",
      "nothing:2\n",
      "now:1\n",
      "now!”:1\n",
      "number:2\n",
      "o:1\n",
      "of:33\n",
      "often:1\n",
      "old:1\n",
      "on:18\n",
      "on,:2\n",
      "on.:1\n",
      "once,:1\n",
      "one:3\n",
      "one.:1\n",
      "only:1\n",
      "onto:2\n",
      "opened:2\n",
      "or:1\n",
      "orange:1\n",
      "other:2\n",
      "ou:1\n",
      "oung:1\n",
      "out:9\n",
      "out.:1\n",
      "outer:1\n",
      "outside:1\n",
      "over:8\n",
      "owls.:1\n",
      "p:7\n",
      "pair:1\n",
      "pan:1\n",
      "passed:1\n",
      "passed.:1\n",
      "patting:1\n",
      "people:1\n",
      "perfect:2\n",
      "perhaps:1\n",
      "petunia:1\n",
      "philosophers:7\n",
      "photographs:2\n",
      "pictures:1\n",
      "pinched:1\n",
      "pink:1\n",
      "place:1\n",
      "place,”:1\n",
      "playing:1\n",
      "poor:1\n",
      "potter:10\n",
      "presents.:1\n",
      "pretend:1\n",
      "privet:3\n",
      "problems,:1\n",
      "prodded:1\n",
      "professor:12\n",
      "pulling:1\n",
      "punching:2\n",
      "put:3\n",
      "put-:1\n",
      "racing:2\n",
      "rapped:1\n",
      "ready:1\n",
      "really:2\n",
      "relieved.:1\n",
      "remember:1\n",
      "reply:1\n",
      "report:1\n",
      "riding:1\n",
      "right:2\n",
      "right,:1\n",
      "road:1\n",
      "roar:2\n",
      "rolled:2\n",
      "room:1\n",
      "room,:1\n",
      "rose:2\n",
      "rowling:7\n",
      "ruf:1\n",
      "rumbling:1\n",
      "s:13\n",
      "s,:1\n",
      "sad,:1\n",
      "said:9\n",
      "said,:1\n",
      "same:3\n",
      "say:1\n",
      "say?”:1\n",
      "saying:2\n",
      "scar:1\n",
      "scars:1\n",
      "scratchy:1\n",
      "scream:1\n",
      "screeched.:1\n",
      "second:1\n",
      "secret:1\n",
      "see:3\n",
      "seemed:1\n",
      "seen:1\n",
      "shaggy:1\n",
      "shall:1\n",
      "shaped:1\n",
      "she:5\n",
      "shone:1\n",
      "shook,:1\n",
      "shoulders:1\n",
      "showed:2\n",
      "shrill:1\n",
      "sign:2\n",
      "silence:1\n",
      "silent:1\n",
      "silver:1\n",
      "simply:1\n",
      "since:1\n",
      "sir:4\n",
      "sir?”:1\n",
      "sirius:1\n",
      "sitting:1\n",
      "size:1\n",
      "skinnier:1\n",
      "skinny:1\n",
      "sky:2\n",
      "sleeve,:1\n",
      "slept:1\n",
      "slept.:1\n",
      "slinking:1\n",
      "slowly:1\n",
      "small:2\n",
      "smaller:1\n",
      "snapped:1\n",
      "so:2\n",
      "sobbed:1\n",
      "socks.:1\n",
      "some:1\n",
      "somebody:1\n",
      "something:3\n",
      "soon,:1\n",
      "sound:2\n",
      "sounding:1\n",
      "special,:1\n",
      "sped:1\n",
      "spend:1\n",
      "spider:1\n",
      "spiders,:1\n",
      "spoke.:1\n",
      "spotted:1\n",
      "stairs:1\n",
      "stand:1\n",
      "start.:1\n",
      "started:2\n",
      "staying:1\n",
      "steadily:1\n",
      "step:1\n",
      "step,:1\n",
      "stepped:1\n",
      "still:1\n",
      "stone:7\n",
      "stood:1\n",
      "stopped:1\n",
      "stove.:1\n",
      "streaming:1\n",
      "street:2\n",
      "street.:2\n",
      "suddenly:3\n",
      "sun:1\n",
      "swallowed,:1\n",
      "swarmin’:1\n",
      "swelled:1\n",
      "swish:1\n",
      "swung:1\n",
      "t:9\n",
      "t.:1\n",
      "tabby:1\n",
      "table:1\n",
      "take:1\n",
      "taking:1\n",
      "tall:1\n",
      "tangles:1\n",
      "television:1\n",
      "ten:1\n",
      "tend:1\n",
      "ter:1\n",
      "than:2\n",
      "that:13\n",
      "that.:1\n",
      "that?”:1\n",
      "the:91\n",
      "their:5\n",
      "them:2\n",
      "them,:2\n",
      "them.:2\n",
      "then:3\n",
      "then,:1\n",
      "there:2\n",
      "there,:1\n",
      "there?”:1\n",
      "they:3\n",
      "thin:1\n",
      "things:1\n",
      "think:1\n",
      "this:3\n",
      "this?”:1\n",
      "though:2\n",
      "thought:1\n",
      "three:1\n",
      "through:1\n",
      "tidy:2\n",
      "time:2\n",
      "times:2\n",
      "to:23\n",
      "too:1\n",
      "too.:1\n",
      "took:3\n",
      "toward:2\n",
      "trash:1\n",
      "tried:1\n",
      "trust:2\n",
      "tucked:1\n",
      "tuft:1\n",
      "turned:3\n",
      "twelve:1\n",
      "twice:1\n",
      "twinkling:1\n",
      "two.:1\n",
      "under:5\n",
      "underneath:1\n",
      "unless:1\n",
      "until:1\n",
      "up:7\n",
      "up!:1\n",
      "up.:1\n",
      "used:1\n",
      "usually:1\n",
      "v:1\n",
      "vast,:1\n",
      "very:7\n",
      "visible,:1\n",
      "voice:1\n",
      "voice,:1\n",
      "voices::1\n",
      "w:4\n",
      "wake:1\n",
      "waking:1\n",
      "walked:2\n",
      "walking:1\n",
      "wall:1\n",
      "want:2\n",
      "wanted:1\n",
      "wanted,:1\n",
      "was:28\n",
      "was.:1\n",
      "we:1\n",
      "wear:1\n",
      "wearing:1\n",
      "weeks:1\n",
      "well:1\n",
      "went:1\n",
      "were:4\n",
      "we’d:1\n",
      "we’ll:1\n",
      "what:3\n",
      "when:2\n",
      "where:3\n",
      "which:2\n",
      "whiskery:1\n",
      "whispered:1\n",
      "whispered,:1\n",
      "who:1\n",
      "why:1\n",
      "wide.:1\n",
      "wild:1\n",
      "wise:1\n",
      "with:8\n",
      "with.”:1\n",
      "without:1\n",
      "woke:1\n",
      "woken:2\n",
      "would:4\n",
      "wouldn’:1\n",
      "wounded:1\n",
      "www.ztcprep.com:10\n",
      "y:1\n",
      "years:2\n",
      "yes,:2\n",
      "yet?”:1\n",
      "you:9\n",
      "yourself,:1\n",
      "you’re:1\n",
      "|:7\n",
      "–:7\n",
      "—:18\n",
      "—”:1\n",
      "“are:1\n",
      "“at:1\n",
      "“borrowed:1\n",
      "“but:2\n",
      "“could:1\n",
      "“couldn’:1\n",
      "“even:1\n",
      "“good:1\n",
      "“hagrid,”:1\n",
      "“hagrid’:1\n",
      "“he’ll:1\n",
      "“i:2\n",
      "“is:1\n",
      "“i’d:1\n",
      "“i’m:1\n",
      "“nearly:1\n",
      "“no:1\n",
      "“no,:1\n",
      "“nothing,:1\n",
      "“s-s-sorry:1\n",
      "“shhh!”:1\n",
      "“t:1\n",
      "“that’:1\n",
      "“up!:1\n",
      "“up!”:1\n",
      "“w:2\n",
      "“what:1\n",
      "“y:6\n",
      "“you’ll:1\n",
      "…:1\n",
      "…”:1\n"
     ]
    }
   ],
   "source": [
    "def mapred(file1_path):\n",
    "    wordcount = {} # Initiating wordcounts variable to count word occurences\n",
    "    with open(file1_path, 'r', encoding='utf-8') as f1:\n",
    "        for line in f1:\n",
    "            mapped_data = map(line)\n",
    "            wordcount = reduce(wordcount, mapped_data)\n",
    "    return wordcount\n",
    "\n",
    "# Defining the map and reduce functions\n",
    "def map(line):\n",
    "    count = {} # Creating count dictionary to get the word and no.of its occurences as the output\n",
    "    line = line.strip()\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        count[word] = count.get(word, 0) + 1\n",
    "    return count\n",
    "\n",
    "def reduce(past_count, new_count):\n",
    "    for word, count in new_count.items():\n",
    "        past_count[word] = past_count.get(word, 0) + count\n",
    "    return past_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file1_path = \"file1.txt\"\n",
    "    wordcount = mapred(file1_path)\n",
    "    for word, count in sorted(wordcount.items()):\n",
    "        print(f\"{word}:{count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "JanjUy-UYjp9",
    "outputId": "02ef0ca7-c5f9-4f43-8ffb-45fbbe1ca394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "FJShlArZu7az",
    "outputId": "c00dfdfb-d9cd-4e36-9218-182f11d9bf20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",: 15\n",
      ",â: 3\n",
      ".: 14\n",
      ".â: 1\n",
      "64: 1\n",
      "65: 1\n",
      "66: 1\n",
      "67: 1\n",
      "68: 1\n",
      "69: 1\n",
      "70: 1\n",
      "?â: 3\n",
      "albus: 2\n",
      "angry?â: 1\n",
      "anything?â: 1\n",
      "anâ: 9\n",
      "ap.: 3\n",
      "arenâ: 1\n",
      "asked,: 1\n",
      "bank.: 1\n",
      "be?: 1\n",
      "beak.: 1\n",
      "beard.: 1\n",
      "bit,: 1\n",
      "boat,: 1\n",
      "boat.: 1\n",
      "boots.: 1\n",
      "born.: 1\n",
      "bottom,: 1\n",
      "boy!: 1\n",
      "business.â: 1\n",
      "cake,: 1\n",
      "change,: 1\n",
      "chuckled.: 1\n",
      "coat.: 2\n",
      "coins,: 1\n",
      "coins.: 1\n",
      "cupboard.â: 1\n",
      "cupboard?: 1\n",
      "daylight,: 1\n",
      "deliverinâ: 1\n",
      "diagon: 1\n",
      "didnâ: 6\n",
      "do.â: 1\n",
      "donâ: 1\n",
      "dream,â: 1\n",
      "dream.: 1\n",
      "dudleyâ: 1\n",
      "dumbledore: 2\n",
      "dumbledore.: 1\n",
      "dumbledore.â: 1\n",
      "dumbledââ: 1\n",
      "eah: 2\n",
      "eh?: 1\n",
      "ernon: 4\n",
      "ernon.: 1\n",
      "ernon;: 1\n",
      "everything.: 1\n",
      "everythinâ?: 1\n",
      "expelled,: 1\n",
      "expelled?â: 1\n",
      "eyebrows.: 1\n",
      "eyes,: 1\n",
      "eyes.: 1\n",
      "f,: 1\n",
      "fact,: 1\n",
      "feet,: 1\n",
      "fer: 7\n",
      "fetchinâ: 1\n",
      "fight.: 1\n",
      "fire.: 1\n",
      "football?: 1\n",
      "gang,: 1\n",
      "ge: 1\n",
      "gettinâ: 2\n",
      "go,: 1\n",
      "goblins,: 1\n",
      "goblins.â: 1\n",
      "going?â: 1\n",
      "goinâ: 1\n",
      "gotta: 2\n",
      "gringotts: 3\n",
      "gringotts.: 2\n",
      "had,: 1\n",
      "hadnâ: 3\n",
      "hagrid: 14\n",
      "hagrid,: 4\n",
      "hagrid.: 3\n",
      "hagrid?â: 1\n",
      "hagridâ: 3\n",
      "haircut,: 1\n",
      "havenâ: 1\n",
      "he,: 1\n",
      "head,: 1\n",
      "head.: 1\n",
      "here?â: 1\n",
      "heâ: 2\n",
      "heâd: 3\n",
      "heâll: 3\n",
      "him,: 2\n",
      "him,â: 2\n",
      "him.: 4\n",
      "him?: 2\n",
      "himself.: 1\n",
      "hissed.: 1\n",
      "hogwarts: 3\n",
      "hogwarts!: 1\n",
      "hogwarts,â: 1\n",
      "hogwarts.: 1\n",
      "hogwarts.â: 1\n",
      "holding.: 1\n",
      "house,: 1\n",
      "humbugs,: 1\n",
      "insul: 1\n",
      "it,: 1\n",
      "it.: 2\n",
      "it?: 1\n",
      "izards: 1\n",
      "izardsâ: 1\n",
      "iâll: 2\n",
      "iâve: 2\n",
      "j.k.: 7\n",
      "keys,: 1\n",
      "knuts,â: 1\n",
      "lar: 1\n",
      "light,: 1\n",
      "mad.: 1\n",
      "magic,: 1\n",
      "magic.â: 1\n",
      "magic?â: 1\n",
      "man,: 1\n",
      "me!â: 1\n",
      "me,: 1\n",
      "meself: 1\n",
      "mistake.: 2\n",
      "morning.: 1\n",
      "muggle: 1\n",
      "mumbled,: 1\n",
      "nah,: 1\n",
      "nameâ: 1\n",
      "noise.: 1\n",
      "on,: 1\n",
      "one.: 1\n",
      "ones.â: 1\n",
      "open.: 1\n",
      "ou: 1\n",
      "oâ: 5\n",
      "pain.: 1\n",
      "payinâ: 1\n",
      "pellets,: 1\n",
      "pig,: 1\n",
      "pigâ: 1\n",
      "pockets.â: 2\n",
      "proud,: 1\n",
      "puncture.: 1\n",
      "revenge,: 1\n",
      "right,â: 1\n",
      "right.â: 1\n",
      "roared.: 1\n",
      "rock.: 1\n",
      "room,: 1\n",
      "rowling: 7\n",
      "said.: 2\n",
      "sausage,: 1\n",
      "school.â: 1\n",
      "second,: 1\n",
      "see.: 1\n",
      "sinking.: 1\n",
      "smiling,: 1\n",
      "sofa,: 1\n",
      "sofa.: 1\n",
      "sort,: 1\n",
      "speakinâ.: 1\n",
      "squeal,: 1\n",
      "storm.: 1\n",
      "strange-looking: 1\n",
      "stretched.: 1\n",
      "string,: 1\n",
      "stuf: 3\n",
      "sunlight,: 1\n",
      "sunlight.: 1\n",
      "surprise,: 1\n",
      "sâpposed: 1\n",
      "teabags: 1\n",
      "teh: 1\n",
      "ter: 19\n",
      "that,â: 2\n",
      "that.: 1\n",
      "that.â: 2\n",
      "them,: 1\n",
      "them.: 2\n",
      "then.â: 1\n",
      "ther: 1\n",
      "there,: 1\n",
      "theyâd: 1\n",
      "theyâre: 1\n",
      "this.: 1\n",
      "thought,: 1\n",
      "thundered,: 1\n",
      "tight.: 1\n",
      "town,: 1\n",
      "tricks!â: 1\n",
      "trousers.: 1\n",
      "truth.: 1\n",
      "up,: 1\n",
      "up.: 1\n",
      "up.â: 1\n",
      "wait,: 1\n",
      "wasnâ: 2\n",
      "weâll: 1\n",
      "weâve: 1\n",
      "wizard,: 2\n",
      "wizard.â: 1\n",
      "wizard?: 1\n",
      "wizards.: 1\n",
      "wonâ: 3\n",
      "world,: 1\n",
      "world.: 1\n",
      "wouldnâ: 1\n",
      "www.ztcprep.com: 10\n",
      "yeh: 7\n",
      "yeh.â: 1\n",
      "yehâd: 1\n",
      "yer: 5\n",
      "ying: 1\n",
      "youâll: 1\n",
      "|: 7\n",
      "â: 7\n",
      "â: 24\n",
      "ââ: 5\n",
      "â: 2\n",
      "âcept: 1\n",
      "â: 2\n",
      "âall: 1\n",
      "âbe: 1\n",
      "âbest: 1\n",
      "âbut: 2\n",
      "âdonâ: 3\n",
      "âdâyeh: 1\n",
      "âflew: 1\n",
      "âgive: 1\n",
      "âgot: 1\n",
      "âgotta: 1\n",
      "âhagrid!â: 1\n",
      "âhagrid,â: 1\n",
      "âharry: 1\n",
      "âhavenâ: 1\n",
      "âhe: 2\n",
      "âheâ: 1\n",
      "âhow: 1\n",
      "âi: 4\n",
      "âif: 1\n",
      "âit: 1\n",
      "âitâ: 1\n",
      "âiâm: 2\n",
      "âjust: 1\n",
      "âknuts?â: 1\n",
      "âmm?â: 1\n",
      "ânever: 1\n",
      "ânot: 1\n",
      "âoh,: 1\n",
      "âpay: 1\n",
      "âsee?â: 1\n",
      "âshouldnâ: 1\n",
      "âstop: 1\n",
      "âthe: 1\n",
      "âthereâ: 1\n",
      "âthey: 1\n",
      "âum: 1\n",
      "âw: 1\n",
      "âwhat?â: 1\n",
      "âwhy: 2\n",
      "ây: 3\n",
      "ââ: 1\n",
      "â¦: 6\n"
     ]
    }
   ],
   "source": [
    "# As my birth year is 2000 I am selecting the pages 100-109 in the book\n",
    "# Comparing each word occurance with the ukenglish words data downloaded from http://www.gwicks.net/dictionaries.html\n",
    "def english_words(file_path):\n",
    "    eng_words = set()\n",
    "    # Opening the file in read mode\n",
    "    with open(file_path, 'r', encoding='latin-1') as engfile:\n",
    "        for line in engfile:\n",
    "            word = line.strip()\n",
    "            eng_words.add(word.lower())\n",
    "    return eng_words\n",
    "\n",
    "# defining the function to solve the question to find non-english words in the pages we selected\n",
    "def non_english_words(file_path, eng_words):\n",
    "    non_eng = {} # Initiating a dictionary to store the non-english words and its no.of occurances\n",
    "    with open(file_path, 'r', encoding='latin-1') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            words = line.split()\n",
    "            for word in words:\n",
    "                word = word.lower()\n",
    "                if word not in eng_words:\n",
    "                    non_eng[word] = non_eng.get(word, 0) + 1\n",
    "    return non_eng\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    eng_words = english_words(\"/content/ukenglish.txt\")\n",
    "    file_path = \"file2.txt\"\n",
    "    non_english_words_found = non_english_words(file_path, eng_words)\n",
    "    for word, count in sorted(non_english_words_found.items()):\n",
    "        print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_T5vZidx5OX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
